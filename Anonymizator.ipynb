{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T20:23:38.234791Z",
     "start_time": "2025-03-11T20:23:37.088254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "from docx import Document\n",
    "\n",
    "def read_docx(file_path):\n",
    "   \n",
    "    document = Document(file_path)\n",
    "    paragraphs = [p.text for p in document.paragraphs]\n",
    "    return \"\\n\".join(paragraphs)\n",
    "\n",
    "def create_nlp_pipeline():\n",
    "    nlp = spacy.load(\"hu_core_news_lg\")\n",
    "    # Insert EntityRuler before the built-in NER\n",
    "    ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "    \n",
    "    #  ADDRESS Pattern \n",
    "    #    Matches: <number> <streetName> <streetSuffix> [optional comma] <city>\n",
    "    #    e.g. \"101 Frog Street, Bogtown\"\n",
    "    address_pattern = [\n",
    "        {\n",
    "            \"label\": \"ADDRESS\",\n",
    "            \"pattern\": [\n",
    "                # Building number\n",
    "                {\"TEXT\": {\"REGEX\": r\"^\\d+$\"}},\n",
    "                # One-word street name (letters only)\n",
    "                {\"TEXT\": {\"REGEX\": r\"^[A-Za-z]+$\"}},\n",
    "                # Street suffix (common examples)\n",
    "                {\"TEXT\": {\"REGEX\": r\"^(Street|St|Road|Rd|Ave|Avenue|Blvd|Boulevard|Lane|Ln)$\"}},\n",
    "                # Optional comma\n",
    "                {\"TEXT\": {\"REGEX\": r\"^,$\"}, \"OP\": \"?\"},\n",
    "                # One-word city name (letters only)\n",
    "                {\"TEXT\": {\"REGEX\": r\"^[A-Za-z]+$\"}}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Coordinates Pattern (COORDINATES)\n",
    "    #    Example: (40.7128, -74.0060)\n",
    "    coordinates_pattern = [\n",
    "        {\n",
    "            \"label\": \"COORDINATES\",\n",
    "            \"pattern\": [\n",
    "                {\"TEXT\": {\"REGEX\": r\"^\\($\"}},                 \n",
    "                {\"TEXT\": {\"REGEX\": r\"^-?\\d+(\\.\\d+)?$\"}},      \n",
    "                {\"TEXT\": {\"REGEX\": r\"^,$\"}},                 \n",
    "                {\"TEXT\": {\"REGEX\": r\"^-?\\d+(\\.\\d+)?$\"}},      \n",
    "                {\"TEXT\": {\"REGEX\": r\"^\\)$\"}}                  \n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    #  Multi-token pattern for 16-digit credit card with optional dashes/spaces\n",
    "    #    Example: \"4111-1111-1111-1111\" or \"4111 1111 1111 1111\"\n",
    "    credit_card_pattern = [\n",
    "        {\n",
    "            \"label\": \"CREDIT_CARD\",\n",
    "            \"pattern\": [\n",
    "                {\"TEXT\": {\"REGEX\": r\"^\\d{4}$\"}},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^[-.\\s]+$\"}, \"OP\": \"?\"},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^\\d{4}$\"}},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^[-.\\s]+$\"}, \"OP\": \"?\"},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^\\d{4}$\"}},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^[-.\\s]+$\"}, \"OP\": \"?\"},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^\\d{4}$\"}}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Multi-token pattern for phone numbers\n",
    "    phone_pattern = [\n",
    "        {\n",
    "            \"label\": \"PHONE_NUMBER\",\n",
    "            \"pattern\": [\n",
    "                {\"TEXT\": {\"REGEX\": r\"^\\+?\\d{1,3}$\"}, \"OP\": \"?\"},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^[-.\\s]+$\"}, \"OP\": \"?\"},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^\\d{3,4}$\"}},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^[-.\\s]+$\"}, \"OP\": \"?\"},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^\\d{3}$\"}},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^[-.\\s]+$\"}, \"OP\": \"?\"},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^\\d{3,4}$\"}}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Other sensitive data patterns\n",
    "    other_patterns = [\n",
    "        {\n",
    "            \"label\": \"EMAIL\",\n",
    "            \"pattern\": [{\"TEXT\": {\"REGEX\": r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\"}}]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"ACCOUNT_NUMBER\",\n",
    "            \"pattern\": [{\"TEXT\": {\"REGEX\": r\"^\\d{6,12}$\"}}]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"ID_NUMBER\",\n",
    "            \"pattern\": [{\"TEXT\": {\"REGEX\": r\"^\\d{11}$\"}}]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # ADDRESS first so it overrides default numeric handling.\n",
    "    patterns = (\n",
    "        address_pattern \n",
    "        + coordinates_pattern \n",
    "        + credit_card_pattern \n",
    "        + phone_pattern \n",
    "        + other_patterns\n",
    "    )\n",
    "    ruler.add_patterns(patterns)\n",
    "    \n",
    "    return nlp\n",
    "\n",
    "def main():\n",
    "    # 1. Path to your DOCX file\n",
    "    file_path = \"C:/Users/Mike/Downloads/FROGS.docx\"\n",
    "    \n",
    "    # 2. Read the text\n",
    "    text = read_docx(file_path)\n",
    "    \n",
    "    # 3. Create the spaCy pipeline\n",
    "    nlp = create_nlp_pipeline()\n",
    "    \n",
    "    # 4. Process the text\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # 5. Define allowed labels (default + custom)\n",
    "    allowed_labels = {\n",
    "        \"PERSON\", \"GPE\", \"ORG\", \"DATE\", \"MONEY\", \n",
    "        \"CARDINAL\", \"NORP\", \"LOC\", \"EMAIL\",\n",
    "        \"PHONE_NUMBER\", \"CREDIT_CARD\", \"ACCOUNT_NUMBER\", \n",
    "        \"ID_NUMBER\", \"COORDINATES\", \"ADDRESS\"\n",
    "    }\n",
    "    \n",
    "    # 6. Print detected entities\n",
    "    print(\"=== Detected Entities ===\")\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in allowed_labels:\n",
    "            print(f\"Text: '{ent.text.strip()}', Label: {ent.label_}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "945eeff1772b9ea4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mike\\anaconda3\\Lib\\site-packages\\spacy\\util.py:910: UserWarning: [W095] Model 'hu_core_news_lg' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Detected Entities ===\n",
      "Text: 'dr.jane@amphibians.edu', Label: EMAIL\n",
      "Text: '123456789', Label: ACCOUNT_NUMBER\n",
      "Text: '101 Frog Street, Bogtown', Label: ADDRESS\n",
      "Text: 'USA', Label: LOC\n",
      "Text: '9876543210', Label: ACCOUNT_NUMBER\n",
      "Text: '(40.7128, -74.0060)', Label: COORDINATES\n",
      "Text: 'michael.brown@frogs.org', Label: EMAIL\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T20:14:35.632253Z",
     "start_time": "2025-03-11T20:14:35.294741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "from docx import Document\n",
    "\n",
    "def create_nlp_pipeline():\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    \n",
    "    # Insert EntityRuler before the built-in NER\n",
    "    ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "\n",
    "    # Example: minimal patterns. Add or remove as needed.\n",
    "    patterns = [\n",
    "        {\n",
    "            \"label\": \"PHONE_NUMBER\",\n",
    "            \"pattern\": [\n",
    "                {\"TEXT\": {\"REGEX\": r\"^\\+?\\d{1,3}$\"}, \"OP\": \"?\"},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^[-.\\s]+$\"}, \"OP\": \"?\"},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^\\d{3,4}$\"}},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^[-.\\s]+$\"}, \"OP\": \"?\"},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^\\d{3}$\"}},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^[-.\\s]+$\"}, \"OP\": \"?\"},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^\\d{3,4}$\"}}\n",
    "            ]\n",
    "        },\n",
    "        \n",
    "         {\n",
    "            \"label\": \"POST_ADDRESS_HU\",\n",
    "            \"pattern\": [\n",
    "                {\"TEXT\": {\"REGEX\": r\"^H-\\d{4}$\"}},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^[A-Za-zÁÉÍÓÖŐÚÜŰáéíóöőúüű]+$\"}}\n",
    "            ]\n",
    "        },\n",
    "        \n",
    "          {\n",
    "            \"label\": \"SALARY_HU\",\n",
    "            \"pattern\": [\n",
    "                {\"TEXT\": {\"REGEX\": r\"^\\d{1,3}(,\\d{3})*$\"}},  # e.g., \"300,000\" or \"300000\"\n",
    "                {\"TEXT\": {\"REGEX\": r\"^(Ft|HUF)$\"}}\n",
    "            ]\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"label\": \"DATE\",\n",
    "            \"pattern\": [\n",
    "                {\"TEXT\": {\"REGEX\": r\"^\\d{1,2}/\\d{1,2}/\\d{4}$\"}}\n",
    "            ]\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"label\": \"ACCOUNT_NUMBER\",\n",
    "            \"pattern\": [{\"TEXT\": {\"REGEX\": r\"^\\d{6,12}$\"}}]\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"label\": \"CREDIT_CARD\",\n",
    "            \"pattern\": [\n",
    "                {\"TEXT\": {\"REGEX\": r\"^\\d{4}$\"}},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^[-.\\s]+$\"}, \"OP\": \"?\"},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^\\d{4}$\"}},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^[-.\\s]+$\"}, \"OP\": \"?\"},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^\\d{4}$\"}},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^[-.\\s]+$\"}, \"OP\": \"?\"},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^\\d{4}$\"}}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"EMAIL\",\n",
    "            \"pattern\": [{\"TEXT\": {\"REGEX\": r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\"}}]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"ID_NUMBER\",\n",
    "            \"pattern\": [{\"TEXT\": {\"REGEX\": r\"^\\d{11}$\"}}]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"COORDINATES\",\n",
    "            \"pattern\": [\n",
    "                {\"TEXT\": {\"REGEX\": r\"^\\($\"}},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^-?\\d+(\\.\\d+)?$\"}},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^,$\"}},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^-?\\d+(\\.\\d+)?$\"}},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^\\)$\"}}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"ADDRESS\",\n",
    "            \"pattern\": [\n",
    "                {\"TEXT\": {\"REGEX\": r\"^\\d+$\"}},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^[A-Za-z]+$\"}},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^(Street|St|Road|Rd|Ave|Avenue|Blvd|Boulevard|Lane|Ln)$\"}},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^,$\"}, \"OP\": \"?\"},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^[A-Za-z]+$\"}}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    ruler.add_patterns(patterns)\n",
    "    return nlp\n",
    "\n",
    "def anonymize_text(text, nlp, allowed_labels):\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    new_text = []\n",
    "    last_end = 0\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        # Only anonymize if label is in the allowed list\n",
    "        if ent.label_ in allowed_labels:\n",
    "            # Add the text from the end of the last entity up to the start of this entity\n",
    "            new_text.append(text[last_end:ent.start_char])\n",
    "            # Insert a placeholder, e.g. [PERSON], [PHONE_NUMBER], etc.\n",
    "            new_text.append(f\"[{ent.label_}]\")\n",
    "            last_end = ent.end_char\n",
    "    \n",
    "    # Add any remaining text after the last entity\n",
    "    new_text.append(text[last_end:])\n",
    "    return \"\".join(new_text)\n",
    "\n",
    "def anonymize_docx(input_path, output_path, nlp, allowed_labels):\n",
    "    doc = Document(input_path)\n",
    "    for paragraph in doc.paragraphs:\n",
    "        original_text = paragraph.text\n",
    "        anonymized = anonymize_text(original_text, nlp, allowed_labels)\n",
    "        paragraph.text = anonymized\n",
    "    \n",
    "    # Save the updated docx\n",
    "    doc.save(output_path)\n",
    "\n",
    "def main():\n",
    "    nlp = create_nlp_pipeline()\n",
    "    \n",
    "    # Labels should\n",
    "    allowed_labels = {\n",
    "        \"PERSON\", \"GPE\", \"ORG\", \"DATE\", \"MONEY\", \"CARDINAL\",\n",
    "        \"NORP\", \"LOC\", \"EMAIL\", \"PHONE_NUMBER\", \"CREDIT_CARD\",\n",
    "        \"ACCOUNT_NUMBER\", \"ID_NUMBER\", \"COORDINATES\", \"ADDRESS\"\n",
    "    }\n",
    "    \n",
    "    # File paths\n",
    "    input_file = \"C:/Users/Mike/Downloads/FROGS.docx\"\n",
    "    output_file = \"C:/Users/Mike/Desktop/AN_DOCX/FROGS_AN.docx\"\n",
    "    \n",
    "    # Anonymize the DOCX\n",
    "    anonymize_docx(input_file, output_file, nlp, allowed_labels)\n",
    "    print(f\"Anonymized docx saved as: {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "226c0075a2ad0a2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anonymized docx saved as: C:/Users/Mike/Desktop/AN_DOCX/FROGS_AN.docx\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "52edd0aedf80cfec"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
